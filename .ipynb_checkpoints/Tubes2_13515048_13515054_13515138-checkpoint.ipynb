{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tubes 2\n",
    "## Feed Forward Neural Network\n",
    "___Alvin Sullivan 13515048___\n",
    "\n",
    "___Albertus Djauhari Djohan 13515054___\n",
    "\n",
    "___Kevin 13515138___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Sebuah Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Neural Network\n",
    "Classifier dibuat dengan sebuah kelas bernama `MultiLayerNN`. Kelas ini berfungsi untuk memodelkan neural network yang mampu melakukan pembelajaran dengan mini-batch stochastic gradient descent. Kelas ini memiliki atribut matriks data input tanpa label, matriks weight dari hidden node, matriks weight dari output node, banyak batch, konstanta learning rate, konstanta tolerance, konstanta momentum, dan banyak epochs. Kelas ini memiliki spesifikasi sebagai berikut.\n",
    "\n",
    "- Jumlah hidden layer maksimal 10\n",
    "- Jumlah node dalam setiap hidden layer dapat bervariasi\n",
    "- Fully-connected layer\n",
    "- Fungsi aktivasi berupa sigmoid untuk semua hidden layer maupun output layer\n",
    "- Node output berjumlah 1\n",
    "- Program memberikan pilihan untuk menggunakan momentum atau tidak\n",
    "- Program mengimplementasikan mini-batch stochastic gradient descent\n",
    "\n",
    "Kelas ini memiliki fungsi `train` untuk melakukan pembelajaran mini-batch stochastic gradient descent. Fungsi train melakukan pembelajaran sesuai dengan epochs dan batch yang ditentukan. Untuk setiap batch dalam epochs, dipanggil fungsi `gradient_descent` yang memanggil tiga fungsi lainnya secara berurutan sesuai algoritma gradient descent. Pertama dipanggil fungsi `feed_forward` untuk menentukan output setiap neuron. Kedua dipanggil fungsi `back_propagation` untuk menentukan delta setiap neuron. Ketiga dipanggil fungsi `update_weight` untuk mengubah weight setiap neuron sesuai dengan hasil dari fungsi-fungsi sebelumnya. Setelah seluruh epochs selesai, maka diperoleh sebuah model neural network dengan representasi matriks weight setiap neuron yang sudah diperbarui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_layer_num = 4\n",
    "var_nodes = [4, 3 , 2, 3 ,1]\n",
    "var_epoch = 10\n",
    "var_batch = 2\n",
    "var_momentum = 0.9\n",
    "var_learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNN:\n",
    "\n",
    "    def __init__(self, data, hidden_node, output_node,\n",
    "        num_batch, learning_rate_const, tolerance_const,\n",
    "        **kwargs):\n",
    "        \n",
    "        self.instance = data\n",
    "        self.w_hidden_node = hidden_node\n",
    "        self.w_output_node = output_node\n",
    "        # Gradient Descent Parameters\n",
    "        self.batch_size = num_batch\n",
    "        self.learning_rate = learning_rate_const\n",
    "        self.tolerance = tolerance_const\n",
    "        self.momentum = kwargs.get('momentum', 0)\n",
    "        self.epochs = kwargs.get('epochs', 10)\n",
    "       \n",
    "    def train(self, instance_target):\n",
    "        instance_target_t = np.array([instance_target]).T\n",
    "        batch_iteration = int(np.ceil(self.instance.shape[0] / self.batch_size))\n",
    "        old_loss = -np.inf\n",
    "        for step in range(self.epochs):\n",
    "            loss = 0\n",
    "            for i in range(batch_iteration):\n",
    "                start_index = i * self.batch_size\n",
    "                end_index = i * self.batch_size + self.batch_size\n",
    "                if end_index > len(instance_target_t):\n",
    "                    end_index = len(instance_target_t)\n",
    "                self.gradient_descent(self.instance[start_index:end_index:1], instance_target_t[start_index:end_index:1])\n",
    "                loss = loss + self.loss_function(self.instance[start_index:end_index:1], instance_target_t[start_index:end_index:1])\n",
    "        # Print Loss\n",
    "            print (\"Loss after epoch %i: %f\" % (step, self.loss_function(self.instance, instance_target)))\n",
    "            \n",
    "            if np.abs(loss - old_loss) < self.tolerance:\n",
    "                break\n",
    "            old_loss = loss\n",
    "    \n",
    "    def feed_forward(self, instance):\n",
    "        s = list()\n",
    "        o = list()\n",
    "        # Feed Forward Hidden Node\n",
    "        s_temp = instance.dot(self.w_hidden_node[0].T)\n",
    "        o_temp = self.sigmoid(s_temp)\n",
    "        s.append(s_temp)\n",
    "        o.append(o_temp)\n",
    "        iteration = len(self.w_hidden_node)\n",
    "        for i in range(1,iteration):\n",
    "            s_temp = o[i-1].dot(self.w_hidden_node[i].T)\n",
    "            o_temp = self.sigmoid(s_temp)\n",
    "            o.append(o_temp)\n",
    "        # Feed Forward Output Node\n",
    "        s_out = o[-1].dot(self.w_output_node.T)\n",
    "        o_out = self.sigmoid(s_out)\n",
    "        return s, o, s_out, o_out\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        output = 1 / (1 + np.exp(-X))\n",
    "        return np.matrix(output)\n",
    "\n",
    "    def loss_function(self, instance, instance_target):\n",
    "        _,_,_,o_out = self.feed_forward(instance)\n",
    "        \n",
    "        squared_error = np.square(instance_target - o_out)\n",
    "        data_loss = np.sum(squared_error) / 2      \n",
    "        return data_loss/len(instance)\n",
    "    \n",
    "    def back_propagation(self, instance_target, o, o_out):\n",
    "        d = list()\n",
    "        # Back Propagation Output Node\n",
    "        d_temp = np.multiply(np.multiply(o_out, 1-o_out), instance_target-o_out)\n",
    "        d.insert(0, d_temp)\n",
    "        # Back Propagation Hidden Node\n",
    "        d_temp = np.multiply(np.multiply(o[-1], 1-o[-1]), (self.w_output_node.T.dot(d[0].T)).T)\n",
    "        d.insert(0, d_temp)\n",
    "        iteration = len(self.w_hidden_node)\n",
    "        for i in range(iteration-1, 0, -1):\n",
    "            d_temp = np.multiply(np.multiply(o[i-1], 1-o[i-1]), (self.w_hidden_node[i].T.dot(d[0].T)).T)\n",
    "            d.insert(0, d_temp)\n",
    "        return d\n",
    "\n",
    "    def update_weight(self, instance, o, d):\n",
    "        # Update Weight Output Node\n",
    "        self.w_output_node[0] = self.w_output_node[0] + self.momentum * self.w_output_node[0] + self.learning_rate * d[-1].T.dot(o[-1])\n",
    "        # Update Weight Hidden Node\n",
    "        iteration = len(self.w_hidden_node)\n",
    "        for i in range(iteration-1, 0, -1):\n",
    "            self.w_hidden_node[i] = self.w_hidden_node[i] + self.momentum * self.w_hidden_node[i] + self.learning_rate * d[i].T.dot(o[i-1])\n",
    "        self.w_hidden_node[0] = self.w_hidden_node[0] + self.momentum * self.w_hidden_node[0] + self.learning_rate * d[0].T.dot(instance)\n",
    "\n",
    "    def gradient_descent(self, instance, instance_target):\n",
    "        # Feed Forward\n",
    "        _,o,_,o_out = self.feed_forward(instance)\n",
    "        # Back Propagation      \n",
    "        d = self.back_propagation(instance_target, o, o_out)\n",
    "        # Update Weight\n",
    "        self.update_weight(instance, o, d)\n",
    "    def predict(self, instance):\n",
    "        _,_,_,o_out = self.feed_forward(instance)\n",
    "#         return np.argmax(o_out,axis=1)\n",
    "        return o_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksekusi Data Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membaca dataset weather dan membentuk data train dan data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[1 0 0 0]\n",
      " [1 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 0 1]\n",
      " [1 0 0 1]\n",
      " [1 0 1 0]\n",
      " [2 0 1 0]\n",
      " [0 1 0 1]\n",
      " [2 0 0 0]\n",
      " [2 1 1 1]\n",
      " [2 0 0 1]\n",
      " [0 1 1 1]]\n",
      "X_test\n",
      "[[2 1 0 1]\n",
      " [2 0 1 1]]\n",
      "y_train\n",
      "[2 0 1 2 0 2 1 1 2 2 1 0]\n",
      "y_test\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "file = \"dataset/weather.csv\"\n",
    "data = pd.read_csv(file)\n",
    "data = data.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "data = data.values\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print('X_train')\n",
    "print(X_train)\n",
    "\n",
    "print('X_test')\n",
    "print(X_test)\n",
    "\n",
    "print('y_train')\n",
    "print(y_train)\n",
    "\n",
    "print('y_test')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier yang Dibuat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inisialisasi matriks weight hidden node dan output node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriks weight hidden node:\n",
      " [array([[ 0.88202617,  0.2000786 ,  0.48936899,  1.1204466 ],\n",
      "       [ 0.933779  , -0.48863894,  0.47504421, -0.0756786 ],\n",
      "       [-0.05160943,  0.20529925,  0.07202179,  0.72713675],\n",
      "       [ 0.38051886,  0.06083751,  0.22193162,  0.16683716]]), array([[ 0.86260696, -0.11844818,  0.18074972, -0.4931124 ],\n",
      "       [-1.47396936,  0.37736687,  0.49908247, -0.42848917],\n",
      "       [ 1.31044344, -0.83967841,  0.02641869, -0.10807065]])]\n",
      "Matriks weight output node:\n",
      " [[1.53277921 1.46935877 0.15494743]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "w1 = np.random.randn(4, 4) / np.sqrt(4)\n",
    "w2 = np.random.randn(3, 4) / np.sqrt(3)\n",
    "w_output_node = np.random.randn(1, 3)\n",
    "w_hidden_node = list()\n",
    "w_hidden_node.append(w1)\n",
    "w_hidden_node.append(w2)\n",
    "print('Matriks weight hidden node:\\n', w_hidden_node)\n",
    "print('Matriks weight output node:\\n', w_output_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat model neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 4.940609\n",
      "Loss after epoch 1: 4.929911\n",
      "Loss after epoch 2: 4.919333\n",
      "Loss after epoch 3: 4.908876\n",
      "Loss after epoch 4: 4.898543\n",
      "Loss after epoch 5: 4.888337\n",
      "Loss after epoch 6: 4.878259\n",
      "Loss after epoch 7: 4.868311\n",
      "Loss after epoch 8: 4.858495\n",
      "Loss after epoch 9: 4.848812\n",
      "Loss after epoch 10: 4.839266\n",
      "Loss after epoch 11: 4.829856\n",
      "Loss after epoch 12: 4.820585\n",
      "Loss after epoch 13: 4.811454\n",
      "Loss after epoch 14: 4.802465\n",
      "Loss after epoch 15: 4.793618\n",
      "Loss after epoch 16: 4.784915\n",
      "Loss after epoch 17: 4.776356\n",
      "Loss after epoch 18: 4.767944\n",
      "Loss after epoch 19: 4.759678\n",
      "Loss after epoch 20: 4.751560\n",
      "Loss after epoch 21: 4.743590\n",
      "Loss after epoch 22: 4.735769\n",
      "Loss after epoch 23: 4.728097\n",
      "Loss after epoch 24: 4.720575\n",
      "Loss after epoch 25: 4.713202\n",
      "Loss after epoch 26: 4.705980\n",
      "Loss after epoch 27: 4.698909\n",
      "Loss after epoch 28: 4.691988\n",
      "Loss after epoch 29: 4.685217\n",
      "Loss after epoch 30: 4.678596\n",
      "Loss after epoch 31: 4.672126\n",
      "Loss after epoch 32: 4.665805\n",
      "Loss after epoch 33: 4.659633\n",
      "Loss after epoch 34: 4.653610\n",
      "Loss after epoch 35: 4.647735\n",
      "Loss after epoch 36: 4.642008\n",
      "Loss after epoch 37: 4.636428\n",
      "Loss after epoch 38: 4.630993\n",
      "Loss after epoch 39: 4.625703\n",
      "Loss after epoch 40: 4.620558\n",
      "Loss after epoch 41: 4.615555\n",
      "Loss after epoch 42: 4.610694\n",
      "Loss after epoch 43: 4.605973\n",
      "Loss after epoch 44: 4.601391\n",
      "Loss after epoch 45: 4.596947\n",
      "Loss after epoch 46: 4.592639\n",
      "Loss after epoch 47: 4.588465\n",
      "Loss after epoch 48: 4.584425\n",
      "Loss after epoch 49: 4.580515\n",
      "Loss after epoch 50: 4.576735\n",
      "Loss after epoch 51: 4.573083\n",
      "Loss after epoch 52: 4.569556\n",
      "Loss after epoch 53: 4.566153\n",
      "Loss after epoch 54: 4.562871\n",
      "Loss after epoch 55: 4.559709\n",
      "Loss after epoch 56: 4.556664\n",
      "Loss after epoch 57: 4.553735\n",
      "Loss after epoch 58: 4.550918\n",
      "Loss after epoch 59: 4.548211\n",
      "Loss after epoch 60: 4.545613\n",
      "Loss after epoch 61: 4.543120\n",
      "Loss after epoch 62: 4.540731\n",
      "Loss after epoch 63: 4.538443\n",
      "Loss after epoch 64: 4.536253\n",
      "Loss after epoch 65: 4.534159\n",
      "Loss after epoch 66: 4.532158\n",
      "Loss after epoch 67: 4.530248\n",
      "Loss after epoch 68: 4.528426\n",
      "Loss after epoch 69: 4.526689\n",
      "Loss after epoch 70: 4.525036\n",
      "Loss after epoch 71: 4.523463\n",
      "Loss after epoch 72: 4.521969\n",
      "Loss after epoch 73: 4.520549\n",
      "Loss after epoch 74: 4.519202\n",
      "Loss after epoch 75: 4.517926\n",
      "Loss after epoch 76: 4.516717\n",
      "Loss after epoch 77: 4.515574\n",
      "Loss after epoch 78: 4.514494\n",
      "Loss after epoch 79: 4.513474\n",
      "Loss after epoch 80: 4.512512\n",
      "Loss after epoch 81: 4.511605\n",
      "Loss after epoch 82: 4.510752\n",
      "Loss after epoch 83: 4.509951\n",
      "Loss after epoch 84: 4.509198\n",
      "Loss after epoch 85: 4.508492\n",
      "Loss after epoch 86: 4.507830\n",
      "Loss after epoch 87: 4.507211\n",
      "Loss after epoch 88: 4.506632\n",
      "Loss after epoch 89: 4.506092\n",
      "Loss after epoch 90: 4.505589\n",
      "Loss after epoch 91: 4.505120\n",
      "Loss after epoch 92: 4.504684\n",
      "Loss after epoch 93: 4.504279\n",
      "Loss after epoch 94: 4.503904\n",
      "Loss after epoch 95: 4.503556\n",
      "Loss after epoch 96: 4.503235\n",
      "Loss after epoch 97: 4.502938\n",
      "Loss after epoch 98: 4.502664\n",
      "Loss after epoch 99: 4.502413\n",
      "Matriks weight hidden node:\n",
      " [matrix([[ 3.57453904,  0.81067424,  1.98314832,  4.54039037],\n",
      "        [ 3.78420068, -1.9800548 ,  1.92506396, -0.3067021 ],\n",
      "        [-0.20241648,  0.83290773,  0.29346101,  2.94554763],\n",
      "        [ 1.5344034 ,  0.24559172,  0.89794928,  0.67794887]]), matrix([[ 3.51716516, -0.45752334,  0.74356021, -1.98004943],\n",
      "        [-5.95946183,  1.54317562,  2.0299509 , -1.72495214],\n",
      "        [ 5.31269089, -3.4002591 ,  0.10823172, -0.4359936 ]])]\n",
      "Matriks weight output node:\n",
      " [[6.24459512 5.96659472 0.66013832]]\n",
      "[[0.99756263]\n",
      " [0.99786592]]\n"
     ]
    }
   ],
   "source": [
    "multiLayerNN = MultiLayerNN(X_train, w_hidden_node, w_output_node, var_batch, var_learning_rate, 1e-6, momentum = var_momentum, epochs = var_epoch)\n",
    "multiLayerNN.train(y_train)\n",
    "print('Matriks weight hidden node:\\n', multiLayerNN.w_hidden_node)\n",
    "print('Matriks weight output node:\\n', multiLayerNN.w_output_node)\n",
    "\n",
    "#x_test = np.matrix([[2,1,1,1],[1,0,0,1]])\n",
    "y_test_res = multiLayerNN.predict(X_test)\n",
    "print(y_test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier menggunakan keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for i in range(0,len(var_nodes)):\n",
    "    if i == 0:\n",
    "        model.add(Dense(units=var_nodes[1], activation='sigmoid', input_dim=var_nodes[0]))\n",
    "        model.add(Dropout(0.1))\n",
    "    elif i == len(var_nodes)-1:\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(units=var_nodes[i+1], activation='sigmoid'))\n",
    "        model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, decay=var_learning_rate, momentum=var_momentum, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=var_batch, nb_epoch=var_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembagian Tugas\n",
    "1. Alvin Sullivan - 13515048 - \n",
    "2. Albertus Djauhari - 13515054 - \n",
    "3. Kevin - 13515138 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
