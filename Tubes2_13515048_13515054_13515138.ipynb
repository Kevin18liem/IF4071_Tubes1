{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tubes 2\n",
    "## Feed Forward Neural Network\n",
    "___Alvin Sullivan 13515048___\n",
    "\n",
    "___Albertus Djauhari Djohan 13515054___\n",
    "\n",
    "___Kevin 13515138___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Sebuah Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Neural Network\n",
    "Classifier dibuat dengan sebuah kelas bernama `MultiLayerNN`. Kelas ini berfungsi untuk memodelkan neural network yang mampu melakukan pembelajaran dengan mini-batch stochastic gradient descent. Kelas ini memiliki atribut matriks data input tanpa label, matriks weight dari hidden node, matriks weight dari output node, banyak batch, konstanta learning rate, konstanta tolerance, konstanta momentum, dan banyak epochs. Kelas ini memiliki spesifikasi sebagai berikut.\n",
    "\n",
    "- Jumlah hidden layer maksimal 10\n",
    "- Jumlah node dalam setiap hidden layer dapat bervariasi\n",
    "- Fully-connected layer\n",
    "- Fungsi aktivasi berupa sigmoid untuk semua hidden layer maupun output layer\n",
    "- Node output berjumlah 1\n",
    "- Program memberikan pilihan untuk menggunakan momentum atau tidak\n",
    "- Program mengimplementasikan mini-batch stochastic gradient descent\n",
    "\n",
    "Kelas ini memiliki fungsi `train` untuk melakukan pembelajaran mini-batch stochastic gradient descent. Fungsi train melakukan pembelajaran sesuai dengan epochs dan batch yang ditentukan. Untuk setiap batch dalam epochs, dipanggil fungsi `gradient_descent` yang memanggil tiga fungsi lainnya secara berurutan sesuai algoritma gradient descent. Pertama dipanggil fungsi `feed_forward` untuk menentukan output setiap neuron. Kedua dipanggil fungsi `back_propagation` untuk menentukan delta setiap neuron. Ketiga dipanggil fungsi `update_weight` untuk mengubah weight setiap neuron sesuai dengan hasil dari fungsi-fungsi sebelumnya. Setelah seluruh epochs selesai, maka diperoleh sebuah model neural network dengan representasi matriks weight setiap neuron yang sudah diperbarui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_layer_num = 4\n",
    "var_nodes = [4, 3 , 2, 3 ,1]\n",
    "var_epoch = 10\n",
    "var_batch = 2\n",
    "var_momentum = 0.9\n",
    "var_learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNN:\n",
    "\n",
    "    def __init__(self, data, hidden_node, output_node,\n",
    "        num_batch, learning_rate_const, tolerance_const,\n",
    "        **kwargs):\n",
    "        \n",
    "        self.instance = data\n",
    "        self.w_hidden_node = hidden_node\n",
    "        self.w_output_node = output_node\n",
    "        # Gradient Descent Parameters\n",
    "        self.batch_size = num_batch\n",
    "        self.learning_rate = learning_rate_const\n",
    "        self.tolerance = tolerance_const\n",
    "        self.momentum = kwargs.get('momentum', 0)\n",
    "        self.epochs = kwargs.get('epochs', 10)\n",
    "       \n",
    "    def train(self, instance_target):\n",
    "        instance_target_t = np.array([instance_target]).T\n",
    "        batch_iteration = int(np.ceil(self.instance.shape[0] / self.batch_size))\n",
    "        old_loss = -np.inf\n",
    "        for step in range(self.epochs):\n",
    "            loss = 0\n",
    "            for i in range(batch_iteration):\n",
    "                start_index = i * self.batch_size\n",
    "                end_index = i * self.batch_size + self.batch_size\n",
    "                if end_index > len(instance_target_t):\n",
    "                    end_index = len(instance_target_t)\n",
    "                self.gradient_descent(self.instance[start_index:end_index:1], instance_target_t[start_index:end_index:1])\n",
    "                loss = loss + self.loss_function(self.instance[start_index:end_index:1], instance_target_t[start_index:end_index:1])\n",
    "        # Print Loss\n",
    "            print (\"Loss after epoch %i: %f\" % (step, self.loss_function(self.instance, instance_target)))\n",
    "            \n",
    "            if np.abs(loss - old_loss) < self.tolerance:\n",
    "                break\n",
    "            old_loss = loss\n",
    "    \n",
    "    def feed_forward(self, instance):\n",
    "        s = list()\n",
    "        o = list()\n",
    "        # Feed Forward Hidden Node\n",
    "        s_temp = instance.dot(self.w_hidden_node[0].T)\n",
    "        o_temp = self.sigmoid(s_temp)\n",
    "        s.append(s_temp)\n",
    "        o.append(o_temp)\n",
    "        iteration = len(self.w_hidden_node)\n",
    "        for i in range(1,iteration):\n",
    "            s_temp = o[i-1].dot(self.w_hidden_node[i].T)\n",
    "            o_temp = self.sigmoid(s_temp)\n",
    "            o.append(o_temp)\n",
    "        # Feed Forward Output Node\n",
    "        s_out = o[-1].dot(self.w_output_node.T)\n",
    "        o_out = self.sigmoid(s_out)\n",
    "        return s, o, s_out, o_out\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        output = 1 / (1 + np.exp(-X))\n",
    "        return np.matrix(output)\n",
    "\n",
    "    def loss_function(self, instance, instance_target):\n",
    "        _,_,_,o_out = self.feed_forward(instance)\n",
    "        \n",
    "        squared_error = np.square(instance_target - o_out)\n",
    "        data_loss = np.sum(squared_error) / 2      \n",
    "        return data_loss/len(instance)\n",
    "    \n",
    "    def back_propagation(self, instance_target, o, o_out):\n",
    "        d = list()\n",
    "        # Back Propagation Output Node\n",
    "        d_temp = np.multiply(np.multiply(o_out, 1-o_out), instance_target-o_out)\n",
    "        d.insert(0, d_temp)\n",
    "        # Back Propagation Hidden Node\n",
    "        d_temp = np.multiply(np.multiply(o[-1], 1-o[-1]), (self.w_output_node.T.dot(d[0].T)).T)\n",
    "        d.insert(0, d_temp)\n",
    "        iteration = len(self.w_hidden_node)\n",
    "        for i in range(iteration-1, 0, -1):\n",
    "            d_temp = np.multiply(np.multiply(o[i-1], 1-o[i-1]), (self.w_hidden_node[i].T.dot(d[0].T)).T)\n",
    "            d.insert(0, d_temp)\n",
    "        return d\n",
    "\n",
    "    def update_weight(self, instance, o, d):\n",
    "        # Update Weight Output Node\n",
    "        self.w_output_node[0] = self.w_output_node[0] + self.momentum * self.w_output_node[0] + self.learning_rate * d[-1].T.dot(o[-1])\n",
    "        # Update Weight Hidden Node\n",
    "        iteration = len(self.w_hidden_node)\n",
    "        for i in range(iteration-1, 0, -1):\n",
    "            self.w_hidden_node[i] = self.w_hidden_node[i] + self.momentum * self.w_hidden_node[i] + self.learning_rate * d[i].T.dot(o[i-1])\n",
    "        self.w_hidden_node[0] = self.w_hidden_node[0] + self.momentum * self.w_hidden_node[0] + self.learning_rate * d[0].T.dot(instance)\n",
    "\n",
    "    def gradient_descent(self, instance, instance_target):\n",
    "        # Feed Forward\n",
    "        _,o,_,o_out = self.feed_forward(instance)\n",
    "        # Back Propagation      \n",
    "        d = self.back_propagation(instance_target, o, o_out)\n",
    "        # Update Weight\n",
    "        self.update_weight(instance, o, d)\n",
    "    def predict(self, instance):\n",
    "        _,_,_,o_out = self.feed_forward(instance)\n",
    "#         return np.argmax(o_out,axis=1)\n",
    "        return o_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksekusi Data Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membaca dataset weather dan membentuk data train dan data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[1 0 0 0]\n",
      " [1 1 0 1]\n",
      " [0 1 1 0]\n",
      " [0 1 0 1]\n",
      " [1 0 0 1]\n",
      " [1 0 1 0]\n",
      " [2 0 1 0]\n",
      " [0 1 0 1]\n",
      " [2 0 0 0]\n",
      " [2 1 1 1]\n",
      " [2 0 0 1]\n",
      " [0 1 1 1]]\n",
      "X_test\n",
      "[[2 1 0 1]\n",
      " [2 0 1 1]]\n",
      "y_train\n",
      "[2 0 1 2 0 2 1 1 2 2 1 0]\n",
      "y_test\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "file = \"dataset/weather.csv\"\n",
    "data = pd.read_csv(file)\n",
    "data = data.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "data = data.values\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print('X_train')\n",
    "print(X_train)\n",
    "\n",
    "print('X_test')\n",
    "print(X_test)\n",
    "\n",
    "print('y_train')\n",
    "print(y_train)\n",
    "\n",
    "print('y_test')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier yang Dibuat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inisialisasi matriks weight hidden node dan output node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriks weight hidden node:\n",
      " [array([[ 0.88202617,  0.2000786 ,  0.48936899,  1.1204466 ],\n",
      "       [ 0.933779  , -0.48863894,  0.47504421, -0.0756786 ],\n",
      "       [-0.05160943,  0.20529925,  0.07202179,  0.72713675],\n",
      "       [ 0.38051886,  0.06083751,  0.22193162,  0.16683716]]), array([[ 0.86260696, -0.11844818,  0.18074972, -0.4931124 ],\n",
      "       [-1.47396936,  0.37736687,  0.49908247, -0.42848917],\n",
      "       [ 1.31044344, -0.83967841,  0.02641869, -0.10807065]])]\n",
      "Matriks weight output node:\n",
      " [[1.53277921 1.46935877 0.15494743]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "w1 = np.random.randn(4, 4) / np.sqrt(4)\n",
    "w2 = np.random.randn(3, 4) / np.sqrt(3)\n",
    "w_output_node = np.random.randn(1, 3)\n",
    "w_hidden_node = list()\n",
    "w_hidden_node.append(w1)\n",
    "w_hidden_node.append(w2)\n",
    "print('Matriks weight hidden node:\\n', w_hidden_node)\n",
    "print('Matriks weight output node:\\n', w_output_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membuat model neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 4.000000\n",
      "Loss after epoch 1: 4.000000\n",
      "Loss after epoch 2: 4.000000\n",
      "Matriks weight hidden node:\n",
      " [matrix([[ 91843.04813005,  20833.65496899,  50956.69646622,\n",
      "         116669.13562695],\n",
      "        [ 97231.93255169, -50880.67811945,  49465.09473308,\n",
      "          -7880.21257501],\n",
      "        [ -5373.95247589,  21377.26683314,   7499.43772988,\n",
      "          75714.82323675],\n",
      "        [ 39622.42057469,   6334.84869502,  23109.15111933,\n",
      "          17372.31198483]]), matrix([[  89820.97795078,  -12333.69344049,   18820.99049921,\n",
      "          -51346.4868605 ],\n",
      "        [-153480.52264421,   39294.21375751,   51968.13599439,\n",
      "          -44617.44141032],\n",
      "        [ 136453.00357054,  -87433.48816727,    2750.90849769,\n",
      "          -11253.10991707]])]\n",
      "Matriks weight output node:\n",
      " [[159604.24115171 153000.43692523  16134.26770481]]\n",
      "[[1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:56: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "multiLayerNN = MultiLayerNN(X_train, w_hidden_node, w_output_node, var_batch, var_learning_rate, 1e-6, momentum = var_momentum, epochs = var_epoch)\n",
    "multiLayerNN.train(y_train)\n",
    "print('Matriks weight hidden node:\\n', multiLayerNN.w_hidden_node)\n",
    "print('Matriks weight output node:\\n', multiLayerNN.w_output_node)\n",
    "\n",
    "#x_test = np.matrix([[2,1,1,1],[1,0,0,1]])\n",
    "y_test_res = multiLayerNN.predict(X_test)\n",
    "print(y_test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier menggunakan keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for i in range(0,len(var_nodes)):\n",
    "    if i == 0:\n",
    "        model.add(Dense(units=var_nodes[1], activation='sigmoid', input_dim=var_nodes[0]))\n",
    "        model.add(Dropout(0.1))\n",
    "    elif i == len(var_nodes)-1:\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(units=var_nodes[i+1], activation='sigmoid'))\n",
    "        model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, decay=var_learning_rate, momentum=var_momentum, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 1.0392 - acc: 0.2500\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.8616 - acc: 0.3333\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5688 - acc: 0.3333\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2704 - acc: 0.3333\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1314 - acc: 0.3333\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0096 - acc: 0.3333 \n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.1132 - acc: 0.3333\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.1711 - acc: 0.3333\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.2435 - acc: 0.3333\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: -0.3040 - acc: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd19e5d1048>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=var_batch, nb_epoch=var_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.306472897529602, 0.5]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pembagian Tugas\n",
    "1. Alvin Sullivan - 13515048 - \n",
    "2. Albertus Djauhari - 13515054 - \n",
    "3. Kevin - 13515138 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
